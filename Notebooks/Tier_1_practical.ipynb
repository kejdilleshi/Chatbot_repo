{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical on Prompt Engineering\n",
    "\n",
    "## Introduction\n",
    "In this practical, we will explore the fundamentals of prompt engineering, a critical skill for effectively interacting with large language models (LLMs). The goal is to learn how different prompt structures impact model responses and to understand best practices for crafting prompts that yield useful results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Choosing the Right Software\n",
    "To run a local language model (LLM) efficiently, you need to choose appropriate software based on your system configuration. Below is a comparison of different software options and links for downloading them.\n",
    "\n",
    "### Available Software Options\n",
    "\n",
    "| **Software** | **Mac**        | **Windows**     | **Linux** |\n",
    "|--------------|-----------------|-----------------|-----------|\n",
    "| **LM Studio** | M1/M2/M3       | Yes             | Yes       |\n",
    "| **OLLAMA**   | MacOS >= 11     | Windows >= 10   | Yes       |\n",
    "| **GPT4all**  | Yes             | Yes             | Yes       |\n",
    "\n",
    "### Download Links\n",
    "- **LM Studio**: [Download here](https://lmstudio.ai/)\n",
    "- **OLLAMA**: [Download here](https://ollama.com/)\n",
    "- **GPT4all**: [Download here](https://www.nomic.ai/gpt4all)\n",
    "\n",
    "\n",
    "## Installation Instructions\n",
    "\n",
    "### Mac\n",
    "1. Download the installer from the corresponding link above.\n",
    "2. Double-click the downloaded file to begin the installation process.\n",
    "3. Follow the on-screen instructions to complete the installation.\n",
    "\n",
    "### Windows\n",
    "1. Visit the provided link and download the installer.\n",
    "2. Run the downloaded `.exe` file.\n",
    "3. Follow the installation wizard steps to set up the software.\n",
    "\n",
    "### Linux\n",
    "1. Download the software package or use a package manager, if available.\n",
    "2. Open the terminal and navigate to the download directory.\n",
    "3. Run the installation command (specific instructions will be provided in the downloaded package documentation).\n",
    "\n",
    "### Help \n",
    "\n",
    "`If you have trouble installing any of the software we provide, raise your hand and we will help you get started`. \n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/OLL.jpg\" alt=\"OLLAMA logo\" style=\"width: 40%; display: inline-block; margin-right: 5%;\" />\n",
    "<img src=\"Images/LMS.jpg\" alt=\"LM Studio logo\" style=\"width: 45%; display: inline-block;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Right Model\n",
    "Selecting an appropriate model is crucial for balancing performance and computational efficiency. Models are typically named according to a specific naming convention that provides details about their size, architecture, and other characteristics.\n",
    "\n",
    "### Naming Convention\n",
    "- **Format**: `[organization or user]/[model architecture]-[model size]-[additional info]`\n",
    "- **Model Size**: Options like small, base, medium, large, xl, or 70b\n",
    "- **Training Data or Task-Specific Indicators**: `Instruct` or `Chat`\n",
    "- **Quantization**: Models are often quantized in formats such as 8-bit or 4-bit to reduce memory usage.\n",
    "\n",
    "### Example Model\n",
    "- **Name**: `[malhajar/meditron-7b-chat-Q4_K_M-GGUF]`\n",
    "- **Quantization**: Q4_K_M / 4-bit\n",
    "- **File Format**: GGUF (Gerganov's Unified Format)\n",
    "- **Task**: Chatbot applications\n",
    "\n",
    "### Recommended Model\n",
    "We suggest using **Mistral-7b-v0.1-GGUF**:\n",
    "- **Quantization**: 4-bit (saves memory and ensures efficient performance)\n",
    "- **Model Size**: 7 billion parameters\n",
    "- **File Format**: GGUF (Gerganov's Unified Format)\n",
    "- **Memory Footprint**: Approximately 4.07GB\n",
    "- **Task**: Suitable for chat and conversational purposes\n",
    "\n",
    "Make sure to select a model that matches your system's capabilities and the specific requirements of your practical work.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Engineering Instructions\n",
    "\n",
    "These are some of the fundamental instructions to create a good prompt: \n",
    "- Use Delimiters for Inputs​\n",
    "\n",
    "    - Summarize the following text: \"Antarctica is the coldest, windiest, and driest continent on Earth.\"​\n",
    "\n",
    "- Specify the Desired Output Format​\n",
    "\n",
    "    - Example: \"Provide the answer as a JSON object with fields for name and age.\"​\n",
    "- Use Constraints or Conditions​\n",
    "\n",
    "    - Example: \"Explain photosynthesis in 50 words or less.\"​\n",
    "- Use Metaprompts to Instruct Model Behavior​\n",
    "\n",
    "    - Example: \"If no information is available, say 'No information found.'\"​\n",
    "\n",
    "\n",
    "\n",
    "### Tasks for Practical Application\n",
    "\n",
    "Based on these instructions and what you learned in the presentation, choose one of the following tasks to practice your prompt engineering skills:\n",
    "\n",
    "1. **Generate a Research Database**\n",
    "   - Create a structured database from research papers in your field. Use the model to extract key information such as the title, authors, publication year, and main findings. Consider specifying the output format as a JSON or CSV to organize your data efficiently.\n",
    "  \n",
    "2. **Write and Analyze Code**\n",
    "   - Use the model to write a piece of code related to your research or area of interest. Then, prompt the model to explain how the code works and why certain approaches were used. This will help you understand both the code structure and the model’s reasoning process.\n",
    "\n",
    "3. **Draft and Interpret Text**\n",
    "   - Ask the model to write a section of text (such as an introduction, summary, or discussion) relevant to your research area. Analyze the output to understand the reasoning and choices the model made in constructing the text. You can also refine the prompt to improve the quality of the writing.\n",
    "\n",
    "4. **Summarize Scientific Articles**\n",
    "   - Provide the model with scientific articles or abstracts and prompt it to summarize the main ideas concisely. Use constraints, such as a word limit or specifying which aspects of the article (methods, results, etc.) to focus on, to tailor the summary to your needs.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
